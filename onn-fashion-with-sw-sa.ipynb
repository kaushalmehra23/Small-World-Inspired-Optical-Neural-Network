{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONN MODEL WITH 10 LAYERS, MLA, SMALL WORLD SKIP CONNECTIONS AND SATURABLE ABSORBER. DATASET FASHION MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T07:24:52.972185Z",
     "iopub.status.busy": "2025-06-24T07:24:52.971673Z",
     "iopub.status.idle": "2025-06-24T07:47:24.707382Z",
     "shell.execute_reply": "2025-06-24T07:47:24.706193Z",
     "shell.execute_reply.started": "2025-06-24T07:24:52.972165Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.4MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 209kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.89MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 22.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training with rewiring_prob = 0.0 ===\n",
      "Epoch 1/15 | Time: 8.2s | Train Loss: 13.3072 | Train Acc: 73.20% | Val Acc: 79.28%\n",
      "Epoch 2/15 | Time: 6.9s | Train Loss: 3.6944 | Train Acc: 79.11% | Val Acc: 79.05%\n",
      "Epoch 3/15 | Time: 6.8s | Train Loss: 0.5688 | Train Acc: 83.34% | Val Acc: 85.17%\n",
      "Epoch 4/15 | Time: 6.9s | Train Loss: 0.5256 | Train Acc: 84.32% | Val Acc: 83.03%\n",
      "Epoch 5/15 | Time: 6.9s | Train Loss: 0.5163 | Train Acc: 84.51% | Val Acc: 84.37%\n",
      "Epoch 6/15 | Time: 6.8s | Train Loss: 0.4605 | Train Acc: 85.75% | Val Acc: 85.58%\n",
      "Epoch 7/15 | Time: 6.8s | Train Loss: 0.4698 | Train Acc: 85.60% | Val Acc: 84.50%\n",
      "Epoch 8/15 | Time: 6.9s | Train Loss: 0.4620 | Train Acc: 85.92% | Val Acc: 84.68%\n",
      "Epoch 9/15 | Time: 6.8s | Train Loss: 0.4536 | Train Acc: 85.90% | Val Acc: 85.80%\n",
      "Epoch 10/15 | Time: 6.9s | Train Loss: 0.4555 | Train Acc: 85.85% | Val Acc: 86.17%\n",
      "Epoch 11/15 | Time: 6.9s | Train Loss: 0.4136 | Train Acc: 86.97% | Val Acc: 85.70%\n",
      "Epoch 12/15 | Time: 6.9s | Train Loss: 0.4078 | Train Acc: 87.08% | Val Acc: 85.35%\n",
      "Epoch 13/15 | Time: 7.0s | Train Loss: 0.4052 | Train Acc: 87.15% | Val Acc: 85.57%\n",
      "Epoch 14/15 | Time: 6.9s | Train Loss: 0.4052 | Train Acc: 87.18% | Val Acc: 86.17%\n",
      "Epoch 15/15 | Time: 7.0s | Train Loss: 0.4063 | Train Acc: 87.07% | Val Acc: 86.32%\n",
      "Best Val Accuracy: 86.32% | Test Accuracy: 85.46%\n",
      "→ p=0.0 Test Accuracy: 85.46%\n",
      "\n",
      "=== Training with rewiring_prob = 0.1 ===\n",
      "Epoch 1/15 | Time: 9.7s | Train Loss: 14.5661 | Train Acc: 76.78% | Val Acc: 80.13%\n",
      "Epoch 2/15 | Time: 9.6s | Train Loss: 1.3424 | Train Acc: 83.21% | Val Acc: 86.58%\n",
      "Epoch 3/15 | Time: 9.6s | Train Loss: 0.4232 | Train Acc: 86.90% | Val Acc: 85.70%\n",
      "Epoch 4/15 | Time: 9.6s | Train Loss: 0.4062 | Train Acc: 87.17% | Val Acc: 86.02%\n",
      "Epoch 5/15 | Time: 9.7s | Train Loss: 0.3933 | Train Acc: 87.52% | Val Acc: 85.87%\n",
      "Epoch 6/15 | Time: 9.6s | Train Loss: 0.3512 | Train Acc: 88.58% | Val Acc: 87.75%\n",
      "Epoch 7/15 | Time: 9.6s | Train Loss: 0.3519 | Train Acc: 88.62% | Val Acc: 87.92%\n",
      "Epoch 8/15 | Time: 9.6s | Train Loss: 0.3427 | Train Acc: 88.81% | Val Acc: 87.57%\n",
      "Epoch 9/15 | Time: 9.6s | Train Loss: 0.3432 | Train Acc: 88.81% | Val Acc: 87.18%\n",
      "Epoch 10/15 | Time: 9.7s | Train Loss: 0.3351 | Train Acc: 89.02% | Val Acc: 87.47%\n",
      "Epoch 11/15 | Time: 9.6s | Train Loss: 0.3021 | Train Acc: 89.94% | Val Acc: 88.28%\n",
      "Epoch 12/15 | Time: 9.7s | Train Loss: 0.2943 | Train Acc: 90.12% | Val Acc: 88.70%\n",
      "Epoch 13/15 | Time: 9.6s | Train Loss: 0.2945 | Train Acc: 90.25% | Val Acc: 88.28%\n",
      "Epoch 14/15 | Time: 9.6s | Train Loss: 0.2912 | Train Acc: 90.31% | Val Acc: 88.02%\n",
      "Epoch 15/15 | Time: 9.6s | Train Loss: 0.2863 | Train Acc: 90.53% | Val Acc: 88.07%\n",
      "Best Val Accuracy: 88.70% | Test Accuracy: 87.82%\n",
      "→ p=0.1 Test Accuracy: 87.82%\n",
      "\n",
      "=== Training with rewiring_prob = 0.2 ===\n",
      "Epoch 1/15 | Time: 10.3s | Train Loss: 18.1738 | Train Acc: 77.04% | Val Acc: 77.27%\n",
      "Epoch 2/15 | Time: 10.4s | Train Loss: 1.3400 | Train Acc: 83.40% | Val Acc: 86.73%\n",
      "Epoch 3/15 | Time: 10.3s | Train Loss: 0.4208 | Train Acc: 86.95% | Val Acc: 85.55%\n",
      "Epoch 4/15 | Time: 10.5s | Train Loss: 0.4051 | Train Acc: 87.29% | Val Acc: 85.73%\n",
      "Epoch 5/15 | Time: 10.4s | Train Loss: 0.3914 | Train Acc: 87.62% | Val Acc: 85.73%\n",
      "Epoch 6/15 | Time: 10.4s | Train Loss: 0.3489 | Train Acc: 88.65% | Val Acc: 87.90%\n",
      "Epoch 7/15 | Time: 10.4s | Train Loss: 0.3500 | Train Acc: 88.59% | Val Acc: 87.65%\n",
      "Epoch 8/15 | Time: 10.4s | Train Loss: 0.3407 | Train Acc: 88.91% | Val Acc: 87.42%\n",
      "Epoch 9/15 | Time: 10.3s | Train Loss: 0.3413 | Train Acc: 88.88% | Val Acc: 87.20%\n",
      "Epoch 10/15 | Time: 10.3s | Train Loss: 0.3330 | Train Acc: 89.15% | Val Acc: 87.63%\n",
      "Epoch 11/15 | Time: 10.4s | Train Loss: 0.3002 | Train Acc: 89.95% | Val Acc: 88.37%\n",
      "Epoch 12/15 | Time: 10.4s | Train Loss: 0.2926 | Train Acc: 90.19% | Val Acc: 88.57%\n",
      "Epoch 13/15 | Time: 10.3s | Train Loss: 0.2929 | Train Acc: 90.24% | Val Acc: 88.10%\n",
      "Epoch 14/15 | Time: 10.3s | Train Loss: 0.2888 | Train Acc: 90.36% | Val Acc: 87.92%\n",
      "Epoch 15/15 | Time: 10.4s | Train Loss: 0.2842 | Train Acc: 90.54% | Val Acc: 88.32%\n",
      "Best Val Accuracy: 88.57% | Test Accuracy: 87.73%\n",
      "→ p=0.2 Test Accuracy: 87.73%\n",
      "\n",
      "=== Training with rewiring_prob = 0.3 ===\n",
      "Epoch 1/15 | Time: 11.9s | Train Loss: 20.1159 | Train Acc: 75.97% | Val Acc: 78.30%\n",
      "Epoch 2/15 | Time: 12.0s | Train Loss: 1.3306 | Train Acc: 82.78% | Val Acc: 85.83%\n",
      "Epoch 3/15 | Time: 12.0s | Train Loss: 0.4280 | Train Acc: 86.77% | Val Acc: 85.38%\n",
      "Epoch 4/15 | Time: 12.0s | Train Loss: 0.4088 | Train Acc: 87.19% | Val Acc: 86.23%\n",
      "Epoch 5/15 | Time: 11.9s | Train Loss: 0.3917 | Train Acc: 87.61% | Val Acc: 85.83%\n",
      "Epoch 6/15 | Time: 12.0s | Train Loss: 0.3499 | Train Acc: 88.66% | Val Acc: 87.78%\n",
      "Epoch 7/15 | Time: 11.9s | Train Loss: 0.3505 | Train Acc: 88.59% | Val Acc: 87.68%\n",
      "Epoch 8/15 | Time: 11.9s | Train Loss: 0.3404 | Train Acc: 88.86% | Val Acc: 87.57%\n",
      "Epoch 9/15 | Time: 11.9s | Train Loss: 0.3402 | Train Acc: 88.95% | Val Acc: 86.82%\n",
      "Epoch 10/15 | Time: 12.0s | Train Loss: 0.3320 | Train Acc: 89.20% | Val Acc: 87.65%\n",
      "Epoch 11/15 | Time: 12.0s | Train Loss: 0.2981 | Train Acc: 90.05% | Val Acc: 87.93%\n",
      "Epoch 12/15 | Time: 11.9s | Train Loss: 0.2904 | Train Acc: 90.35% | Val Acc: 88.38%\n",
      "Epoch 13/15 | Time: 11.9s | Train Loss: 0.2901 | Train Acc: 90.37% | Val Acc: 87.95%\n",
      "Epoch 14/15 | Time: 11.9s | Train Loss: 0.2858 | Train Acc: 90.38% | Val Acc: 87.97%\n",
      "Epoch 15/15 | Time: 12.0s | Train Loss: 0.2811 | Train Acc: 90.62% | Val Acc: 88.12%\n",
      "Best Val Accuracy: 88.38% | Test Accuracy: 87.75%\n",
      "→ p=0.3 Test Accuracy: 87.75%\n",
      "\n",
      "=== Training with rewiring_prob = 0.5 ===\n",
      "Epoch 1/15 | Time: 13.1s | Train Loss: 25.3223 | Train Acc: 76.31% | Val Acc: 78.17%\n",
      "Epoch 2/15 | Time: 13.2s | Train Loss: 1.3276 | Train Acc: 82.63% | Val Acc: 86.00%\n",
      "Epoch 3/15 | Time: 13.1s | Train Loss: 0.4297 | Train Acc: 86.74% | Val Acc: 85.47%\n",
      "Epoch 4/15 | Time: 13.1s | Train Loss: 0.4100 | Train Acc: 87.19% | Val Acc: 85.90%\n",
      "Epoch 5/15 | Time: 13.1s | Train Loss: 0.3944 | Train Acc: 87.55% | Val Acc: 85.80%\n",
      "Epoch 6/15 | Time: 13.1s | Train Loss: 0.3523 | Train Acc: 88.69% | Val Acc: 87.75%\n",
      "Epoch 7/15 | Time: 13.1s | Train Loss: 0.3524 | Train Acc: 88.51% | Val Acc: 87.60%\n",
      "Epoch 8/15 | Time: 13.1s | Train Loss: 0.3425 | Train Acc: 88.90% | Val Acc: 87.48%\n",
      "Epoch 9/15 | Time: 13.1s | Train Loss: 0.3427 | Train Acc: 88.84% | Val Acc: 87.08%\n",
      "Epoch 10/15 | Time: 13.1s | Train Loss: 0.3341 | Train Acc: 89.08% | Val Acc: 87.47%\n",
      "Epoch 11/15 | Time: 13.1s | Train Loss: 0.3002 | Train Acc: 90.00% | Val Acc: 88.20%\n",
      "Epoch 12/15 | Time: 13.2s | Train Loss: 0.2922 | Train Acc: 90.23% | Val Acc: 88.60%\n",
      "Epoch 13/15 | Time: 13.2s | Train Loss: 0.2912 | Train Acc: 90.34% | Val Acc: 88.18%\n",
      "Epoch 14/15 | Time: 13.1s | Train Loss: 0.2873 | Train Acc: 90.38% | Val Acc: 87.87%\n",
      "Epoch 15/15 | Time: 13.1s | Train Loss: 0.2829 | Train Acc: 90.54% | Val Acc: 88.33%\n",
      "Best Val Accuracy: 88.60% | Test Accuracy: 87.73%\n",
      "→ p=0.5 Test Accuracy: 87.73%\n",
      "\n",
      "=== Training with rewiring_prob = 0.7 ===\n",
      "Epoch 1/15 | Time: 16.7s | Train Loss: 90.4327 | Train Acc: 75.92% | Val Acc: 80.22%\n",
      "Epoch 2/15 | Time: 16.8s | Train Loss: 1.1833 | Train Acc: 83.51% | Val Acc: 87.00%\n",
      "Epoch 3/15 | Time: 16.7s | Train Loss: 0.4120 | Train Acc: 87.33% | Val Acc: 86.17%\n",
      "Epoch 4/15 | Time: 16.7s | Train Loss: 0.3877 | Train Acc: 87.82% | Val Acc: 87.17%\n",
      "Epoch 5/15 | Time: 16.7s | Train Loss: 0.3736 | Train Acc: 88.18% | Val Acc: 86.43%\n",
      "Epoch 6/15 | Time: 16.7s | Train Loss: 0.3305 | Train Acc: 89.32% | Val Acc: 88.42%\n",
      "Epoch 7/15 | Time: 16.7s | Train Loss: 0.3281 | Train Acc: 89.29% | Val Acc: 88.15%\n",
      "Epoch 8/15 | Time: 16.7s | Train Loss: 0.3207 | Train Acc: 89.52% | Val Acc: 87.20%\n",
      "Epoch 9/15 | Time: 16.7s | Train Loss: 0.3198 | Train Acc: 89.55% | Val Acc: 88.00%\n",
      "Epoch 10/15 | Time: 16.7s | Train Loss: 0.3121 | Train Acc: 89.83% | Val Acc: 87.93%\n",
      "Epoch 11/15 | Time: 16.7s | Train Loss: 0.2788 | Train Acc: 90.76% | Val Acc: 88.67%\n",
      "Epoch 12/15 | Time: 16.7s | Train Loss: 0.2702 | Train Acc: 90.96% | Val Acc: 88.85%\n",
      "Epoch 13/15 | Time: 16.7s | Train Loss: 0.2680 | Train Acc: 90.99% | Val Acc: 88.18%\n",
      "Epoch 14/15 | Time: 16.7s | Train Loss: 0.2642 | Train Acc: 91.19% | Val Acc: 88.12%\n",
      "Epoch 15/15 | Time: 16.7s | Train Loss: 0.2596 | Train Acc: 91.28% | Val Acc: 88.30%\n",
      "Best Val Accuracy: 88.85% | Test Accuracy: 87.63%\n",
      "→ p=0.7 Test Accuracy: 87.63%\n",
      "\n",
      "=== Training with rewiring_prob = 1.0 ===\n",
      "Epoch 1/15 | Time: 19.9s | Train Loss: 381.9730 | Train Acc: 75.28% | Val Acc: 81.02%\n",
      "Epoch 2/15 | Time: 19.9s | Train Loss: 1.2377 | Train Acc: 83.17% | Val Acc: 86.45%\n",
      "Epoch 3/15 | Time: 19.9s | Train Loss: 0.4196 | Train Acc: 87.02% | Val Acc: 86.38%\n",
      "Epoch 4/15 | Time: 19.9s | Train Loss: 0.3892 | Train Acc: 87.78% | Val Acc: 86.88%\n",
      "Epoch 5/15 | Time: 19.9s | Train Loss: 0.3754 | Train Acc: 88.03% | Val Acc: 86.35%\n",
      "Epoch 6/15 | Time: 19.9s | Train Loss: 0.3305 | Train Acc: 89.24% | Val Acc: 88.45%\n",
      "Epoch 7/15 | Time: 19.9s | Train Loss: 0.3288 | Train Acc: 89.20% | Val Acc: 88.22%\n",
      "Epoch 8/15 | Time: 19.9s | Train Loss: 0.3212 | Train Acc: 89.58% | Val Acc: 87.08%\n",
      "Epoch 9/15 | Time: 19.9s | Train Loss: 0.3190 | Train Acc: 89.61% | Val Acc: 88.00%\n",
      "Epoch 10/15 | Time: 19.9s | Train Loss: 0.3117 | Train Acc: 89.76% | Val Acc: 88.22%\n",
      "Epoch 11/15 | Time: 19.9s | Train Loss: 0.2785 | Train Acc: 90.68% | Val Acc: 88.78%\n",
      "Epoch 12/15 | Time: 19.9s | Train Loss: 0.2690 | Train Acc: 90.96% | Val Acc: 88.77%\n",
      "Epoch 13/15 | Time: 19.9s | Train Loss: 0.2665 | Train Acc: 91.05% | Val Acc: 88.48%\n",
      "Epoch 14/15 | Time: 19.9s | Train Loss: 0.2627 | Train Acc: 91.18% | Val Acc: 88.30%\n",
      "Epoch 15/15 | Time: 20.0s | Train Loss: 0.2577 | Train Acc: 91.32% | Val Acc: 88.58%\n",
      "Best Val Accuracy: 88.78% | Test Accuracy: 87.88%\n",
      "→ p=1.0 Test Accuracy: 87.88%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "# --- Config ---\n",
    "detector_layout = [3, 4, 3]  # three rows: 3,4,3 detectors = 10 classes\n",
    "wavelength = 480e-9\n",
    "image_size = 14\n",
    "tiles = 6\n",
    "output_size = tiles * image_size  # 84\n",
    "min_skip_distance = 2  # Minimum layers to skip\n",
    "max_skip_distance = 7  # Maximum skip distance\n",
    "\n",
    "# Saturable absorber base parameters\n",
    "base_A0 = 0.1\n",
    "base_I_sat = 5e6\n",
    "base_A_ns = 0.005\n",
    "\n",
    "# Training parameters\n",
    "epochs = 15\n",
    "patience = 5\n",
    "\n",
    "# --- Device ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# --- Dataset (FashionMNIST) ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "full_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)  # FashionMNIST dataset\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)  # FashionMNIST dataset\n",
    "\n",
    "# Create train / validation split\n",
    "total_train = len(full_train)\n",
    "val_size = int(0.1 * total_train)\n",
    "train_size = total_train - val_size\n",
    "train_dataset, val_dataset = random_split(full_train, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# --- Model definitions ---\n",
    "class OpticalLayer(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "        self.phase = nn.Parameter(torch.randn(size, size) * 0.1)\n",
    "\n",
    "    def forward(self, x, kernel):\n",
    "        x = x * torch.exp(1j * self.phase)\n",
    "        x_fft = torch.fft.fft2(x)\n",
    "        x_fft = x_fft * kernel\n",
    "        return torch.fft.ifft2(x_fft)\n",
    "\n",
    "class FastONNRandomSkipSA(nn.Module):\n",
    "    def __init__(self, num_layers=10, cascade_sas=2):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.layers = nn.ModuleList([OpticalLayer(output_size) for _ in range(num_layers)])\n",
    "        self.detector_scale = nn.Parameter(torch.tensor([10.0], dtype=torch.float32))\n",
    "        self.fft_grid = self._create_fft_grid().to(device)\n",
    "        self.detector_masks = self._create_detector_masks().to(device)\n",
    "\n",
    "        # Generate random skip connections using the global rewiring_prob\n",
    "        self.skip_connections = self._generate_random_connections()\n",
    "        self.skip_weights = nn.ParameterDict()\n",
    "        self.skip_phases = nn.ParameterDict()\n",
    "\n",
    "        for src, tgt in self.skip_connections:\n",
    "            key = f\"{src}_{tgt}\"\n",
    "            self.skip_weights[key] = nn.Parameter(torch.tensor(0.5))\n",
    "            self.skip_phases[key] = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    def _generate_random_connections(self):\n",
    "        connections = []\n",
    "        for src in range(self.num_layers - min_skip_distance):\n",
    "            max_tgt = min(src + max_skip_distance, self.num_layers - 1)\n",
    "            for tgt in range(src + min_skip_distance, max_tgt + 1):\n",
    "                if random.random() < rewiring_prob:\n",
    "                    connections.append((src, tgt))\n",
    "        return connections\n",
    "\n",
    "    def _create_fft_grid(self):\n",
    "        fx = torch.fft.fftfreq(output_size, d=1e-6)\n",
    "        fy = torch.fft.fftfreq(output_size, d=1e-6)\n",
    "        FX, FY = torch.meshgrid(fx, fy, indexing='xy')\n",
    "        k = 2 * np.pi / wavelength\n",
    "        arg = torch.clamp(1 - (wavelength * FX)**2 - (wavelength * FY)**2, 0.0)\n",
    "        return torch.exp(1j * k * torch.sqrt(arg))\n",
    "\n",
    "    def _create_detector_masks(self):\n",
    "        masks = []\n",
    "        H = W = output_size\n",
    "        rows = len(detector_layout)\n",
    "        band_h = H // rows\n",
    "        for r, cols in enumerate(detector_layout):\n",
    "            cell_w = W // cols\n",
    "            det_h = band_h\n",
    "            y0 = r * band_h\n",
    "            y1 = y0 + det_h\n",
    "            for c in range(cols):\n",
    "                x0 = c * cell_w\n",
    "                x1 = x0 + cell_w\n",
    "                m = torch.zeros(H, W)\n",
    "                m[y0:y1, x0:x1] = 1.0\n",
    "                masks.append(m)\n",
    "        return torch.stack(masks)\n",
    "\n",
    "    def tile_input(self, x):\n",
    "        B = x.size(0)\n",
    "        x = x.view(B, 1, 1, image_size, image_size)\n",
    "        x = x.repeat(1, tiles, tiles, 1, 1)\n",
    "        x = x.permute(0, 1, 3, 2, 4).reshape(B, output_size, output_size)\n",
    "        return x.to(torch.complex64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tile_input(x)\n",
    "        intermediate_outputs = {}\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            for (src, tgt) in self.skip_connections:\n",
    "                if tgt == layer_idx and src in intermediate_outputs:\n",
    "                    key = f\"{src}_{tgt}\"\n",
    "                    weight = torch.sigmoid(self.skip_weights[key])\n",
    "                    phase_corr = torch.exp(1j * self.skip_phases[key])\n",
    "                    x = x + weight * (intermediate_outputs[src] * phase_corr)\n",
    "            x = self.layers[layer_idx](x, self.fft_grid)\n",
    "            intermediate_outputs[layer_idx] = x.clone()\n",
    "\n",
    "        intensity = x.real**2 + x.imag**2\n",
    "        raw = (intensity.unsqueeze(1) * self.detector_masks.unsqueeze(0)).sum(dim=(2, 3))\n",
    "        return raw * self.detector_scale\n",
    "\n",
    "# --- Training & Evaluation ---\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in loader:\n",
    "            imgs, lbls = imgs.squeeze(1).to(device), lbls.to(device)\n",
    "            out = model(imgs)\n",
    "            preds = out.argmax(1)\n",
    "            correct += preds.eq(lbls).sum().item()\n",
    "            total += lbls.size(0)\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, test_loader, epochs=15, lr=0.01):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        start = time.time()\n",
    "\n",
    "        for imgs, lbls in train_loader:\n",
    "            imgs, lbls = imgs.squeeze(1).to(device), lbls.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(imgs)\n",
    "            loss = criterion(out, lbls)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * lbls.size(0)\n",
    "            preds = out.argmax(1)\n",
    "            correct += preds.eq(lbls).sum().item()\n",
    "            total += lbls.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "        train_acc = 100.0 * correct / total\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        duration = time.time() - start\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} | Time: {duration:.1f}s | \"\n",
    "              f\"Train Loss: {total_loss/total:.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        best_val_acc = max(best_val_acc, val_acc)\n",
    "\n",
    "    test_acc = evaluate(model, test_loader)\n",
    "    print(f\"Best Val Accuracy: {best_val_acc:.2f}% | Test Accuracy: {test_acc:.2f}%\")\n",
    "    return test_acc\n",
    "\n",
    "# --- Hyperparameter sweep on rewiring_prob ---\n",
    "for p in [0.0, 0.1, 0.2, 0.3, 0.5, 0.7, 1.0]:\n",
    "    rewiring_prob = p\n",
    "    print(f\"\\n=== Training with rewiring_prob = {p} ===\")\n",
    "    random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    model = FastONNRandomSkipSA(num_layers=10, cascade_sas=2).to(device)\n",
    "    acc = train_model(model, train_loader, val_loader, test_loader, epochs=15, lr=0.01)\n",
    "    print(f\"→ p={p} Test Accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
