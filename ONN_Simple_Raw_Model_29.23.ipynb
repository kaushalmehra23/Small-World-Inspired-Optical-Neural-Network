{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g73T2vZA90kO",
        "outputId": "8d29b321-f287-4242-869c-47163bbd3856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Trainable parameters: 237,728\n",
            "Epoch 1/50 | Train Loss: 2.2118 | Train Acc: 20.76% | Test Acc: 25.61%\n",
            "Epoch 2/50 | Train Loss: 2.0838 | Train Acc: 26.74% | Test Acc: 27.79%\n",
            "Epoch 3/50 | Train Loss: 2.0634 | Train Acc: 27.87% | Test Acc: 28.97%\n",
            "Epoch 4/50 | Train Loss: 2.0565 | Train Acc: 28.41% | Test Acc: 28.83%\n",
            "Epoch 5/50 | Train Loss: 2.0526 | Train Acc: 28.70% | Test Acc: 29.00%\n",
            "Epoch 6/50 | Train Loss: 2.0506 | Train Acc: 28.88% | Test Acc: 29.32%\n",
            "Epoch 7/50 | Train Loss: 2.0488 | Train Acc: 28.98% | Test Acc: 29.03%\n",
            "Epoch 8/50 | Train Loss: 2.0478 | Train Acc: 28.85% | Test Acc: 28.94%\n",
            "Epoch 9/50 | Train Loss: 2.0465 | Train Acc: 29.12% | Test Acc: 28.93%\n",
            "Epoch 10/50 | Train Loss: 2.0456 | Train Acc: 28.99% | Test Acc: 29.03%\n",
            "Epoch 11/50 | Train Loss: 2.0447 | Train Acc: 29.14% | Test Acc: 28.64%\n",
            "Epoch 12/50 | Train Loss: 2.0442 | Train Acc: 29.17% | Test Acc: 29.32%\n",
            "Epoch 13/50 | Train Loss: 2.0419 | Train Acc: 29.32% | Test Acc: 28.77%\n",
            "Epoch 14/50 | Train Loss: 2.0416 | Train Acc: 29.38% | Test Acc: 29.03%\n",
            "Epoch 15/50 | Train Loss: 2.0411 | Train Acc: 29.26% | Test Acc: 28.91%\n",
            "Epoch 16/50 | Train Loss: 2.0408 | Train Acc: 29.34% | Test Acc: 29.05%\n",
            "Epoch 17/50 | Train Loss: 2.0407 | Train Acc: 29.31% | Test Acc: 29.01%\n",
            "Epoch 18/50 | Train Loss: 2.0401 | Train Acc: 29.46% | Test Acc: 29.00%\n",
            "Epoch 19/50 | Train Loss: 2.0392 | Train Acc: 29.46% | Test Acc: 29.04%\n",
            "Epoch 20/50 | Train Loss: 2.0390 | Train Acc: 29.52% | Test Acc: 29.08%\n",
            "Epoch 21/50 | Train Loss: 2.0387 | Train Acc: 29.36% | Test Acc: 29.08%\n",
            "Epoch 22/50 | Train Loss: 2.0387 | Train Acc: 29.47% | Test Acc: 29.07%\n",
            "Epoch 23/50 | Train Loss: 2.0386 | Train Acc: 29.46% | Test Acc: 29.24%\n",
            "Epoch 24/50 | Train Loss: 2.0382 | Train Acc: 29.50% | Test Acc: 29.01%\n",
            "Epoch 25/50 | Train Loss: 2.0377 | Train Acc: 29.50% | Test Acc: 29.18%\n",
            "Epoch 26/50 | Train Loss: 2.0376 | Train Acc: 29.50% | Test Acc: 29.16%\n",
            "Epoch 27/50 | Train Loss: 2.0376 | Train Acc: 29.48% | Test Acc: 29.18%\n",
            "Epoch 28/50 | Train Loss: 2.0375 | Train Acc: 29.61% | Test Acc: 29.12%\n",
            "Epoch 29/50 | Train Loss: 2.0375 | Train Acc: 29.50% | Test Acc: 29.20%\n",
            "Epoch 30/50 | Train Loss: 2.0374 | Train Acc: 29.57% | Test Acc: 29.22%\n",
            "Epoch 31/50 | Train Loss: 2.0371 | Train Acc: 29.59% | Test Acc: 29.21%\n",
            "Epoch 32/50 | Train Loss: 2.0370 | Train Acc: 29.54% | Test Acc: 29.13%\n",
            "Epoch 33/50 | Train Loss: 2.0370 | Train Acc: 29.54% | Test Acc: 29.27%\n",
            "Epoch 34/50 | Train Loss: 2.0369 | Train Acc: 29.65% | Test Acc: 29.18%\n",
            "Epoch 35/50 | Train Loss: 2.0369 | Train Acc: 29.56% | Test Acc: 29.07%\n",
            "Epoch 36/50 | Train Loss: 2.0369 | Train Acc: 29.63% | Test Acc: 29.14%\n",
            "Epoch 37/50 | Train Loss: 2.0367 | Train Acc: 29.59% | Test Acc: 29.18%\n",
            "Epoch 38/50 | Train Loss: 2.0367 | Train Acc: 29.60% | Test Acc: 29.18%\n",
            "Epoch 39/50 | Train Loss: 2.0367 | Train Acc: 29.62% | Test Acc: 29.12%\n",
            "Epoch 40/50 | Train Loss: 2.0366 | Train Acc: 29.58% | Test Acc: 29.19%\n",
            "Epoch 41/50 | Train Loss: 2.0366 | Train Acc: 29.61% | Test Acc: 29.16%\n",
            "Epoch 42/50 | Train Loss: 2.0366 | Train Acc: 29.59% | Test Acc: 29.17%\n",
            "Epoch 43/50 | Train Loss: 2.0365 | Train Acc: 29.58% | Test Acc: 29.19%\n",
            "Epoch 44/50 | Train Loss: 2.0365 | Train Acc: 29.59% | Test Acc: 29.18%\n",
            "Epoch 45/50 | Train Loss: 2.0365 | Train Acc: 29.58% | Test Acc: 29.19%\n",
            "Epoch 46/50 | Train Loss: 2.0365 | Train Acc: 29.59% | Test Acc: 29.18%\n",
            "Epoch 47/50 | Train Loss: 2.0365 | Train Acc: 29.62% | Test Acc: 29.22%\n",
            "Epoch 48/50 | Train Loss: 2.0365 | Train Acc: 29.61% | Test Acc: 29.22%\n",
            "Epoch 49/50 | Train Loss: 2.0364 | Train Acc: 29.61% | Test Acc: 29.20%\n",
            "Epoch 50/50 | Train Loss: 2.0364 | Train Acc: 29.60% | Test Acc: 29.19%\n",
            "Best Test Accuracy: 29.32%\n",
            "Total training time: 17 min 48 sec\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import time\n",
        "\n",
        "class FastONNCore(nn.Module):\n",
        "    \"\"\"Optical processing unit with a 5×5 MLA over a 15×15 input.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        wavelength=480e-9,\n",
        "        dx=1e-6,\n",
        "        dy=1e-6,\n",
        "        z_dist=186.6e-3,\n",
        "        num_layers=15,\n",
        "        tiles=5,            # 5×5 MLA\n",
        "        tile_size=3,         # each lenslet is 3×3\n",
        "              # small-world params:\n",
        "        sw_m=2,         # local span (how many previous layers to link)\n",
        "        sw_p=0.2,       # rewiring prob\n",
        "        sw_trainable=True,  # if True, learn weights for small-world links\n",
        "        sw_init_gamma=0.1,    # initial scale for small-world links\n",
        "        sw_seed=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.wavelength = wavelength\n",
        "        self.dx = dx\n",
        "        self.dy = dy\n",
        "        self.num_layers = num_layers\n",
        "        self.z_list = [z_dist] * num_layers\n",
        "        self.tiles = tiles\n",
        "        self.tile_size = tile_size\n",
        "        self.output_size = tiles * tile_size  # 5 × 3 = 15\n",
        "        self.hub = HubModule(self.output_size, hidden=128)  # Add to init\n",
        "\n",
        "        self.amp_list = nn.ParameterList([\n",
        "            nn.Parameter(0.5 * torch.ones(self.output_size, self.output_size))\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.phase_list = nn.ParameterList([\n",
        "            nn.Parameter(torch.zeros(self.output_size, self.output_size))\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Precompute the FFT grid for propagation (15×15)\n",
        "        self.register_buffer('fft_grid', self._create_fft_grid(), persistent=False)\n",
        "        # Detector: 10 regions tiled over the 15×15 output\n",
        "        self.register_buffer('detector_masks', self._create_detector_masks(), persistent=False)\n",
        "        # Indices to rebuild a 15×15 composite mask from 25 small 3×3 tiles\n",
        "        # self._mask_indices = self._create_mask_indices()\n",
        "\n",
        "    def _create_fft_grid(self):\n",
        "        H = W = self.output_size  # 15\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        fx = torch.fft.fftfreq(W, d=self.dx, device=device)\n",
        "        fy = torch.fft.fftfreq(H, d=self.dy, device=device)\n",
        "        FX, FY = torch.meshgrid(fx, fy, indexing='xy')\n",
        "\n",
        "        k = 2 * np.pi / self.wavelength\n",
        "        arg = 1.0 - (self.wavelength * FX) ** 2 - (self.wavelength * FY) ** 2\n",
        "        arg = torch.clamp(arg, min=0.0)\n",
        "        return torch.sqrt(arg)\n",
        "\n",
        "    def _create_detector_masks(self):\n",
        "        H = W = self.output_size  # 15\n",
        "        masks = torch.zeros(10, H, W)\n",
        "\n",
        "        # Partition 15×15 into 10 regions (3 rows with 3 regions, 1 row with 1 region)\n",
        "        for i in range(10):\n",
        "            row = i // 3\n",
        "            col = i % 3\n",
        "\n",
        "            # Compute row boundaries\n",
        "            h_start = int(row * H / 4)\n",
        "            if row < 3:\n",
        "                h_end = int((row + 1) * H / 4)\n",
        "            else:\n",
        "                h_end = H  # Last row takes remaining space\n",
        "\n",
        "            # Compute column boundaries\n",
        "            if row < 3:\n",
        "                w_start = int(col * W / 3)\n",
        "                w_end = int((col + 1) * W / 3)\n",
        "            else:\n",
        "                w_start = 0\n",
        "                w_end = W  # Last row spans full width\n",
        "\n",
        "            masks[i, h_start:h_end, w_start:w_end] = 1.0\n",
        "\n",
        "        return masks\n",
        "\n",
        "    def propagate(self, U, z):\n",
        "        k = 2 * np.pi / self.wavelength\n",
        "        H_transfer = torch.exp(1j * k * z * self.fft_grid)  # (15×15)\n",
        "        U_fft = torch.fft.fft2(U)\n",
        "        U_prop = torch.fft.ifft2(U_fft * H_transfer)\n",
        "        return U_prop\n",
        "\n",
        "    def tile_input(self, U0):\n",
        "        \"\"\"\n",
        "        U0: (B, H_in, W_in) with H_in=W_in=15.\n",
        "        We split each 15×15 U0 into 25 patches of size 3×3 → build a 15×15 complex field.\n",
        "        \"\"\"\n",
        "        if U0.ndim == 4:\n",
        "                U0 = U0.squeeze(1)  # (B, 15, 15)\n",
        "\n",
        "        return U0.to(torch.complex64)\n",
        "\n",
        "        # return U_tiled\n",
        "\n",
        "    def forward(self, U0):\n",
        "\n",
        "        U = self.tile_input(U0)  # (B, 15, 15) complex\n",
        "\n",
        "\n",
        "\n",
        "        history = []                   # ← Step 1: initialize history\n",
        "        # skip_k, α, β = 3, 0.1, 0.1     # hop length & scaling\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "\n",
        "            phase = torch.clamp(self.phase_list[i], -np.pi, np.pi)       # (15,15)\n",
        "            Mi = self.amp_list[i] * torch.exp(1j * phase)                # (15,15)\n",
        "            U = U * Mi\n",
        "\n",
        "            U = self.propagate(U, self.z_list[i])                        # (B,15,15) complex\n",
        "\n",
        "\n",
        "\n",
        "        I = U.real*2 + U.imag*2  # (B,15,15) real\n",
        "        logits = (I.unsqueeze(1) * self.detector_masks.unsqueeze(0)).sum(dim=(2, 3))\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class RGB_FastONN(nn.Module):\n",
        "    \"\"\"Optical NN with parallel RGB processing paths using a 5×5 MLA over 15×15 per channel.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        wavelengths=480e-9,\n",
        "        dx=1e-6,\n",
        "        dy=1e-6,\n",
        "        z_dist=186.6e-3,\n",
        "        num_layers=15,      # 15 layers per color path\n",
        "        tiles=5,            # 5×5 MLA\n",
        "        tile_size=3,        # each lenslet is 3×3\n",
        "        hidden_size=64\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.core = FastONNCore(\n",
        "            wavelength=wavelengths,\n",
        "            dx=dx, dy=dy,\n",
        "            z_dist=z_dist,\n",
        "            num_layers=num_layers,\n",
        "            tiles=tiles,\n",
        "            tile_size=tile_size\n",
        "        )\n",
        "\n",
        "\n",
        "        # Electronic fusion MLP (3×10 → hidden_size → 10)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(30, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_size, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.core(x[:, 0])      # remove channel dim\n",
        "        return self.fc(out)\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return 100. * correct / total\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, test_loader, epochs=50, lr=0.001):\n",
        "    device = next(model.parameters()).device\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='max', factor=0.5, patience=5, verbose=True\n",
        "    )\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss, total_correct, total_samples = 0, 0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Gentle phase regularization\n",
        "            phase_reg = 0.0\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, FastONNCore):\n",
        "                    for p in module.phase_list:\n",
        "                        phase_reg += 0.001 * p.abs().mean()\n",
        "            loss += phase_reg\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_correct += predicted.eq(labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "        train_loss = total_loss / total_samples\n",
        "        train_acc = 100.0 * total_correct / total_samples\n",
        "\n",
        "        test_acc = evaluate(model, test_loader)\n",
        "        scheduler.step(test_acc)\n",
        "\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            torch.save(model.state_dict(), \"best_rgb_onn_model.pth\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "    return best_acc\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    start_time = time.time()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Fixed transforms for RGB (3 channels)\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Grayscale(),\n",
        "        transforms.Resize(16),\n",
        "        transforms.CenterCrop(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))  # RGB normalization\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Grayscale(),\n",
        "        transforms.Resize(16),\n",
        "        transforms.CenterCrop(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    # Download datasets\n",
        "    train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=train_transform)\n",
        "    test_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=test_transform)\n",
        "\n",
        "\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # Instantiate model\n",
        "    model = FastONNCore(\n",
        "\n",
        "        wavelength=480e-9,\n",
        "        num_layers=15,\n",
        "        tiles=5,\n",
        "        tile_size=3,\n",
        "\n",
        "    ).to(device)\n",
        "    # model = torch.compile(model)\n",
        "\n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Trainable parameters: {total_params:,}\")\n",
        "\n",
        "    # Train the model\n",
        "    best_acc = train_model(\n",
        "        model, train_loader, test_loader,\n",
        "        epochs=50,\n",
        "        lr=0.001\n",
        "    )\n",
        "    print(f\"Best Test Accuracy: {best_acc:.2f}%\")\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    minutes = int(elapsed_time // 60)\n",
        "    seconds = int(elapsed_time % 60)\n",
        "    print(f\"Total training time: {minutes} min {seconds} sec\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TRiiIvqO-FVg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}