{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g73T2vZA90kO",
        "outputId": "1604db0f-5113-4f63-de8b-b23eb8cda891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Trainable parameters: 10,636,035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 | Train Loss: 1.9578 | Train Acc: 29.82% | Test Acc: 40.66%\n",
            "Epoch 2/15 | Train Loss: 1.6349 | Train Acc: 42.41% | Test Acc: 45.37%\n",
            "Epoch 3/15 | Train Loss: 1.5577 | Train Acc: 45.45% | Test Acc: 46.89%\n",
            "Epoch 4/15 | Train Loss: 1.5026 | Train Acc: 47.56% | Test Acc: 48.99%\n",
            "Epoch 5/15 | Train Loss: 1.4659 | Train Acc: 48.87% | Test Acc: 49.86%\n",
            "Epoch 6/15 | Train Loss: 1.4350 | Train Acc: 49.98% | Test Acc: 51.09%\n",
            "Epoch 7/15 | Train Loss: 1.4080 | Train Acc: 51.08% | Test Acc: 51.67%\n",
            "Epoch 8/15 | Train Loss: 1.3838 | Train Acc: 51.66% | Test Acc: 52.14%\n",
            "Epoch 9/15 | Train Loss: 1.3614 | Train Acc: 52.64% | Test Acc: 52.65%\n",
            "Epoch 10/15 | Train Loss: 1.3432 | Train Acc: 53.10% | Test Acc: 53.21%\n",
            "Epoch 11/15 | Train Loss: 1.3248 | Train Acc: 53.86% | Test Acc: 53.82%\n",
            "Epoch 12/15 | Train Loss: 1.3076 | Train Acc: 54.61% | Test Acc: 54.01%\n",
            "Epoch 13/15 | Train Loss: 1.2956 | Train Acc: 54.89% | Test Acc: 54.35%\n",
            "Epoch 14/15 | Train Loss: 1.2784 | Train Acc: 55.50% | Test Acc: 54.12%\n",
            "Epoch 15/15 | Train Loss: 1.2651 | Train Acc: 55.95% | Test Acc: 55.19%\n",
            "Best Test Accuracy: 55.19%\n",
            "Total training time: 98 min 38 sec\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import time\n",
        "\n",
        "class FastONNCore(nn.Module):\n",
        "    \"\"\"Optical processing unit with a 5×5 MLA over a 15×15 input.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        wavelength=480e-9,\n",
        "        dx=1e-6,\n",
        "        dy=1e-6,\n",
        "        z_dist=186.6e-3,\n",
        "        num_layers=10,\n",
        "        tiles=5,            # 5×5 MLA\n",
        "        tile_size=3,         # each lenslet is 3×3\n",
        "              # small-world params:\n",
        "        sw_m=2,         # local span (how many previous layers to link)\n",
        "        sw_p=0.2,       # rewiring prob\n",
        "        sw_trainable=True,  # if True, learn weights for small-world links\n",
        "        sw_init_gamma=0.1,    # initial scale for small-world links\n",
        "        sw_seed=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.wavelength = wavelength\n",
        "        self.dx = dx\n",
        "        self.dy = dy\n",
        "        self.num_layers = num_layers\n",
        "        self.z_list = [z_dist] * num_layers\n",
        "        self.tiles = tiles\n",
        "        self.tile_size = tile_size\n",
        "        self.output_size = tiles * tile_size  # 5 × 3 = 15\n",
        "        self.hub = HubModule(self.output_size, hidden=128)  # Add to init\n",
        "\n",
        "\n",
        "        self.amp_list = nn.ParameterList([\n",
        "            nn.Parameter(0.5 * torch.ones(self.output_size, self.output_size))\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.phase_list = nn.ParameterList([\n",
        "            nn.Parameter(torch.zeros(self.output_size, self.output_size))\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Precompute the FFT grid for propagation (15×15)\n",
        "        self.register_buffer('fft_grid', self._create_fft_grid(), persistent=False)\n",
        "        # Detector: 10 regions tiled over the 15×15 output\n",
        "        self.register_buffer('detector_masks', self._create_detector_masks(), persistent=False)\n",
        "\n",
        "\n",
        "    def _create_fft_grid(self):\n",
        "        H = W = self.output_size  # 15\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        fx = torch.fft.fftfreq(W, d=self.dx, device=device)\n",
        "        fy = torch.fft.fftfreq(H, d=self.dy, device=device)\n",
        "        FX, FY = torch.meshgrid(fx, fy, indexing='xy')\n",
        "\n",
        "        k = 2 * np.pi / self.wavelength\n",
        "        arg = 1.0 - (self.wavelength * FX) ** 2 - (self.wavelength * FY) ** 2\n",
        "        arg = torch.clamp(arg, min=0.0)\n",
        "        return torch.sqrt(arg)\n",
        "\n",
        "    def _create_detector_masks(self):\n",
        "        H = W = self.output_size  # 15\n",
        "        masks = torch.zeros(10, H, W)\n",
        "\n",
        "        # Partition 15×15 into 10 regions (3 rows with 3 regions, 1 row with 1 region)\n",
        "        for i in range(10):\n",
        "            row = i // 3\n",
        "            col = i % 3\n",
        "\n",
        "            # Compute row boundaries\n",
        "            h_start = int(row * H / 4)\n",
        "            if row < 3:\n",
        "                h_end = int((row + 1) * H / 4)\n",
        "            else:\n",
        "                h_end = H  # Last row takes remaining space\n",
        "\n",
        "            # Compute column boundaries\n",
        "            if row < 3:\n",
        "                w_start = int(col * W / 3)\n",
        "                w_end = int((col + 1) * W / 3)\n",
        "            else:\n",
        "                w_start = 0\n",
        "                w_end = W  # Last row spans full width\n",
        "\n",
        "            masks[i, h_start:h_end, w_start:w_end] = 1.0\n",
        "\n",
        "        return masks\n",
        "\n",
        "    def propagate(self, U, z):\n",
        "        k = 2 * np.pi / self.wavelength\n",
        "        H_transfer = torch.exp(1j * k * z * self.fft_grid)  # (15×15)\n",
        "        U_fft = torch.fft.fft2(U)\n",
        "        U_prop = torch.fft.ifft2(U_fft * H_transfer)\n",
        "        return U_prop\n",
        "\n",
        "    def tile_input(self, U0):\n",
        "        \"\"\"\n",
        "        U0: (B, H_in, W_in) with H_in=W_in=15.\n",
        "        We split each 15×15 U0 into 25 patches of size 3×3 → build a 15×15 complex field.\n",
        "        \"\"\"\n",
        "        B, H, W = U0.shape  # H=W=15\n",
        "        return U0.to(torch.complex64)\n",
        "\n",
        "\n",
        "    def forward(self, U0):\n",
        "        \"\"\"\n",
        "        U0: (B, H_in, W_in) with H_in=W_in=15 (grayscale per channel).\n",
        "        1) tile_input → (B, 15, 15) complex\n",
        "        2) For each of the num_layers:\n",
        "            a) build composite mask (15×15) from 25 learned 3×3 tiles\n",
        "            b) multiply U * M, then propagate\n",
        "        3) Compute intensity → (B, 15,15) real → apply 10 detectors → (B,10) logits\n",
        "        \"\"\"\n",
        "        U = self.tile_input(U0)  # (B, 15, 15) complex\n",
        "\n",
        "        history = []                   # ← Step 1: initialize history\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            phase = torch.clamp(self.phase_list[i], -np.pi, np.pi)       # (15,15)\n",
        "            Mi = self.amp_list[i] * torch.exp(1j * phase)                # (15,15)\n",
        "            U = U * Mi\n",
        "\n",
        "            U = self.propagate(U, self.z_list[i])                        # (B,15,15) complex\n",
        "            '''\n",
        "            #  --- Small-world aggregation ---\n",
        "            neigh = [j for j in self.sw_neighbors[i] if j < len(history) and history[j] is not None]\n",
        "            k_i = len(neigh)\n",
        "            if k_i > 0:\n",
        "              if self.sw_trainable:\n",
        "                weights_sw = self.sw_weights[i][:k_i] # Select only weights for valid neighbors\n",
        "                norm = math.sqrt(k_i)\n",
        "                for idx_j, j in enumerate(neigh):\n",
        "                  gamma_ij = weights_sw[idx_j] / norm\n",
        "                  U = U + gamma_ij * history[j]\n",
        "              else:\n",
        "                scale = self.sw_gamma / math.sqrt(k_i)\n",
        "                for j in neigh:\n",
        "                  U = U + scale * history[j]\n",
        "            # ----------------------------------\n",
        "\n",
        "            # 3) Append the *final* U for this layer\n",
        "            history.append(U)\n",
        "            '''\n",
        "\n",
        "        # Ensure U is not None before calculating intensity\n",
        "        if U is not None:\n",
        "            I = U.real*2 + U.imag*2  # (B,15,15) real\n",
        "            logits = (I.unsqueeze(1) * self.detector_masks.unsqueeze(0)).sum(dim=(2, 3))\n",
        "        else:\n",
        "            # Handle the case where U might still be None (e.g., num_layers is 0)\n",
        "            logits = torch.zeros(U0.shape[0], 10, device=U0.device) # Or handle as appropriate\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "class HubModule(nn.Module):\n",
        "    def __init__(self, input_size, hidden=128):\n",
        "        super().__init__()\n",
        "        flat_dim = input_size * input_size\n",
        "        # Adjust input size to handle potentially fewer tensors\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(3 * flat_dim * 2, hidden),  # Max 3 previous layers, real+imag\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, flat_dim * 2)       # real+imag output\n",
        "        )\n",
        "        self.input_size = input_size\n",
        "\n",
        "    def forward(self, tensors):  # tensors: list of complex 2D fields\n",
        "        # Filter out None tensors and handle empty list\n",
        "        valid_tensors = [t for t in tensors if t is not None]\n",
        "        if not valid_tensors:\n",
        "            # Return a zero tensor of the expected output shape\n",
        "            return torch.zeros(1, self.input_size, self.input_size, dtype=torch.complex64, device=self.fc[0].weight.device)\n",
        "\n",
        "        # Split real and imag parts\n",
        "        reals = [t.real.view(t.shape[0], -1) for t in valid_tensors]\n",
        "        imags = [t.imag.view(t.shape[0], -1) for t in valid_tensors]\n",
        "\n",
        "        # Pad with zeros if fewer than 3 tensors\n",
        "        while len(reals) < 3:\n",
        "            reals.append(torch.zeros_like(reals[0]))\n",
        "            imags.append(torch.zeros_like(imags[0]))\n",
        "\n",
        "        x = torch.cat(reals + imags, dim=1)  # concat all\n",
        "        out = self.fc(x)\n",
        "        real_part, imag_part = out.chunk(2, dim=1)\n",
        "        complex_out = torch.complex(real_part, imag_part).view(\n",
        "            valid_tensors[0].shape[0], self.input_size, self.input_size)\n",
        "        return complex_out\n",
        "\n",
        "\n",
        "\n",
        "class RGB_FastONN_Ensemble(nn.Module):\n",
        "    def __init__(self, base_model_cls, n_models=15, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.models = nn.ModuleList([\n",
        "            base_model_cls(*args, **kwargs) for _ in range(n_models)\n",
        "        ])\n",
        "        self.weights = nn.Parameter(torch.ones(n_models) / n_models)  # learnable or fixed weights\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = []\n",
        "        for model in self.models:\n",
        "            out = model(x)  # shape: (B, 10)\n",
        "            outputs.append(out)\n",
        "        stacked = torch.stack(outputs, dim=0)  # shape: (30, B, 10)\n",
        "        weighted = self.weights.view(-1, 1, 1) * stacked\n",
        "        return weighted.sum(dim=0)  # shape: (B, 10)\n",
        "\n",
        "\n",
        "class RGB_FastONN(nn.Module):\n",
        "    \"\"\"Optical NN with parallel RGB processing paths using a 5×5 MLA over 15×15 per channel.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        wavelengths=[650e-9, 530e-9, 470e-9],\n",
        "        dx=1e-6,\n",
        "        dy=1e-6,\n",
        "        z_dist=186.6e-3,\n",
        "        num_layers=10,      # 15 layers per color path\n",
        "        tiles=5,            # 5×5 MLA\n",
        "        tile_size=3,        # each lenslet is 3×3\n",
        "        hidden_size=64\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.red_path = FastONNCore(\n",
        "            wavelength=wavelengths[0],\n",
        "            dx=dx, dy=dy,\n",
        "            z_dist=z_dist,\n",
        "            num_layers=num_layers,\n",
        "            tiles=tiles,\n",
        "            tile_size=tile_size\n",
        "        )\n",
        "        self.green_path = FastONNCore(\n",
        "            wavelength=wavelengths[1],\n",
        "            dx=dx, dy=dy,\n",
        "            z_dist=z_dist,\n",
        "            num_layers=num_layers,\n",
        "            tiles=tiles,\n",
        "            tile_size=tile_size\n",
        "        )\n",
        "        self.blue_path = FastONNCore(\n",
        "            wavelength=wavelengths[2],\n",
        "            dx=dx, dy=dy,\n",
        "            z_dist=z_dist,\n",
        "            num_layers=num_layers,\n",
        "            tiles=tiles,\n",
        "            tile_size=tile_size\n",
        "        )\n",
        "\n",
        "        # Electronic fusion MLP (3×10 → hidden_size → 10)\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(30, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_size, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, 3, 15, 15) after transforms and CenterCrop\n",
        "        r_out = self.red_path(x[:, 0])    # (B,10)\n",
        "        g_out = self.green_path(x[:, 1])  # (B,10)\n",
        "        b_out = self.blue_path(x[:, 2])   # (B,10)\n",
        "\n",
        "        combined = torch.cat([r_out, g_out, b_out], dim=1)  # (B,30)\n",
        "        return self.fusion(combined)                        # (B,10)\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return 100. * correct / total\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, test_loader, epochs=15, lr=0.001):\n",
        "    device = next(model.parameters()).device\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='max', factor=0.5, patience=5, verbose=True\n",
        "    )\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss, total_correct, total_samples = 0, 0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Gentle phase regularization\n",
        "            phase_reg = 0.0\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, FastONNCore):\n",
        "                    for p in module.phase_list:\n",
        "                        phase_reg += 0.001 * p.abs().mean()\n",
        "            loss += phase_reg\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_correct += predicted.eq(labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "        train_loss = total_loss / total_samples\n",
        "        train_acc = 100.0 * total_correct / total_samples\n",
        "\n",
        "        test_acc = evaluate(model, test_loader)\n",
        "        scheduler.step(test_acc)\n",
        "\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            torch.save(model.state_dict(), \"best_rgb_onn_model.pth\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "    return best_acc\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    start_time = time.time()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Fixed transforms for RGB (3 channels)\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize(16),\n",
        "        transforms.CenterCrop(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # RGB normalization\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize(16),\n",
        "        transforms.CenterCrop(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    # Download datasets\n",
        "    train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=train_transform)\n",
        "    test_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=test_transform)\n",
        "\n",
        "\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # Instantiate model\n",
        "    model = RGB_FastONN_Ensemble(\n",
        "        base_model_cls = RGB_FastONN,\n",
        "        n_models = 15,\n",
        "        wavelengths=[650e-9, 530e-9, 470e-9],\n",
        "        num_layers=10,\n",
        "        tiles=5,\n",
        "        tile_size=3,\n",
        "        hidden_size=64\n",
        "    ).to(device)\n",
        "    # model = torch.compile(model)\n",
        "\n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Trainable parameters: {total_params:,}\")\n",
        "\n",
        "    # Train the model\n",
        "    best_acc = train_model(\n",
        "        model, train_loader, test_loader,\n",
        "        epochs=15,\n",
        "        lr=0.001\n",
        "    )\n",
        "    print(f\"Best Test Accuracy: {best_acc:.2f}%\")\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    minutes = int(elapsed_time // 60)\n",
        "    seconds = int(elapsed_time % 60)\n",
        "    print(f\"Total training time: {minutes} min {seconds} sec\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TRiiIvqO-FVg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}