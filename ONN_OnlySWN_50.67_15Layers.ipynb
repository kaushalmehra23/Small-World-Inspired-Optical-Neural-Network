{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g73T2vZA90kO",
        "outputId": "d9a881fc-8304-41fa-9678-9034301c5323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 49.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 715,899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 | Train Loss: 2.0466 | Train Acc: 24.28% | Test Acc: 33.90%\n",
            "Epoch 2/50 | Train Loss: 1.8292 | Train Acc: 34.23% | Test Acc: 37.52%\n",
            "Epoch 3/50 | Train Loss: 1.7740 | Train Acc: 36.35% | Test Acc: 39.80%\n",
            "Epoch 4/50 | Train Loss: 1.7333 | Train Acc: 38.07% | Test Acc: 41.64%\n",
            "Epoch 5/50 | Train Loss: 1.7052 | Train Acc: 39.35% | Test Acc: 42.43%\n",
            "Epoch 6/50 | Train Loss: 1.6784 | Train Acc: 40.65% | Test Acc: 43.28%\n",
            "Epoch 7/50 | Train Loss: 1.6584 | Train Acc: 41.32% | Test Acc: 44.03%\n",
            "Epoch 8/50 | Train Loss: 1.6435 | Train Acc: 42.03% | Test Acc: 44.96%\n",
            "Epoch 9/50 | Train Loss: 1.6316 | Train Acc: 42.39% | Test Acc: 44.77%\n",
            "Epoch 10/50 | Train Loss: 1.6195 | Train Acc: 42.83% | Test Acc: 45.35%\n",
            "Epoch 11/50 | Train Loss: 1.6052 | Train Acc: 43.50% | Test Acc: 45.47%\n",
            "Epoch 12/50 | Train Loss: 1.5962 | Train Acc: 43.90% | Test Acc: 45.77%\n",
            "Epoch 13/50 | Train Loss: 1.5903 | Train Acc: 43.78% | Test Acc: 46.58%\n",
            "Epoch 14/50 | Train Loss: 1.5792 | Train Acc: 44.48% | Test Acc: 46.68%\n",
            "Epoch 15/50 | Train Loss: 1.5719 | Train Acc: 44.71% | Test Acc: 46.59%\n",
            "Epoch 16/50 | Train Loss: 1.5634 | Train Acc: 44.84% | Test Acc: 46.88%\n",
            "Epoch 17/50 | Train Loss: 1.5572 | Train Acc: 45.37% | Test Acc: 47.65%\n",
            "Epoch 18/50 | Train Loss: 1.5492 | Train Acc: 45.29% | Test Acc: 47.48%\n",
            "Epoch 19/50 | Train Loss: 1.5440 | Train Acc: 45.57% | Test Acc: 47.90%\n",
            "Epoch 20/50 | Train Loss: 1.5416 | Train Acc: 45.70% | Test Acc: 47.92%\n",
            "Epoch 21/50 | Train Loss: 1.5340 | Train Acc: 46.04% | Test Acc: 48.47%\n",
            "Epoch 22/50 | Train Loss: 1.5302 | Train Acc: 46.39% | Test Acc: 48.32%\n",
            "Epoch 23/50 | Train Loss: 1.5294 | Train Acc: 46.27% | Test Acc: 48.47%\n",
            "Epoch 24/50 | Train Loss: 1.5220 | Train Acc: 46.31% | Test Acc: 48.63%\n",
            "Epoch 25/50 | Train Loss: 1.5197 | Train Acc: 46.39% | Test Acc: 48.76%\n",
            "Epoch 26/50 | Train Loss: 1.5148 | Train Acc: 46.73% | Test Acc: 48.90%\n",
            "Epoch 27/50 | Train Loss: 1.5092 | Train Acc: 47.04% | Test Acc: 48.96%\n",
            "Epoch 28/50 | Train Loss: 1.5059 | Train Acc: 46.83% | Test Acc: 49.11%\n",
            "Epoch 29/50 | Train Loss: 1.5066 | Train Acc: 46.94% | Test Acc: 49.00%\n",
            "Epoch 30/50 | Train Loss: 1.5008 | Train Acc: 47.31% | Test Acc: 49.18%\n",
            "Epoch 31/50 | Train Loss: 1.4988 | Train Acc: 47.21% | Test Acc: 49.37%\n",
            "Epoch 32/50 | Train Loss: 1.4935 | Train Acc: 47.26% | Test Acc: 49.31%\n",
            "Epoch 33/50 | Train Loss: 1.4948 | Train Acc: 47.58% | Test Acc: 49.67%\n",
            "Epoch 34/50 | Train Loss: 1.4905 | Train Acc: 47.47% | Test Acc: 49.30%\n",
            "Epoch 35/50 | Train Loss: 1.4912 | Train Acc: 47.49% | Test Acc: 49.44%\n",
            "Epoch 36/50 | Train Loss: 1.4871 | Train Acc: 47.78% | Test Acc: 49.59%\n",
            "Epoch 37/50 | Train Loss: 1.4852 | Train Acc: 47.78% | Test Acc: 49.15%\n",
            "Epoch 38/50 | Train Loss: 1.4790 | Train Acc: 48.20% | Test Acc: 49.30%\n",
            "Epoch 39/50 | Train Loss: 1.4805 | Train Acc: 47.97% | Test Acc: 49.40%\n",
            "Epoch 40/50 | Train Loss: 1.4699 | Train Acc: 48.57% | Test Acc: 50.03%\n",
            "Epoch 41/50 | Train Loss: 1.4673 | Train Acc: 48.39% | Test Acc: 50.06%\n",
            "Epoch 42/50 | Train Loss: 1.4650 | Train Acc: 48.49% | Test Acc: 50.37%\n",
            "Epoch 43/50 | Train Loss: 1.4646 | Train Acc: 48.63% | Test Acc: 50.14%\n",
            "Epoch 44/50 | Train Loss: 1.4603 | Train Acc: 48.92% | Test Acc: 50.12%\n",
            "Epoch 45/50 | Train Loss: 1.4629 | Train Acc: 48.50% | Test Acc: 50.23%\n",
            "Epoch 46/50 | Train Loss: 1.4615 | Train Acc: 48.60% | Test Acc: 50.21%\n",
            "Epoch 47/50 | Train Loss: 1.4630 | Train Acc: 48.72% | Test Acc: 50.01%\n",
            "Epoch 48/50 | Train Loss: 1.4601 | Train Acc: 48.84% | Test Acc: 50.07%\n",
            "Epoch 49/50 | Train Loss: 1.4538 | Train Acc: 49.30% | Test Acc: 50.67%\n",
            "Epoch 50/50 | Train Loss: 1.4535 | Train Acc: 48.91% | Test Acc: 50.57%\n",
            "Best Test Accuracy: 50.67%\n",
            "Total training time: 34 min 30 sec\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import time\n",
        "\n",
        "class FastONNCore(nn.Module):\n",
        "    \"\"\"Optical processing unit with a 5×5 MLA over a 15×15 input.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        wavelength=480e-9,\n",
        "        dx=1e-6,\n",
        "        dy=1e-6,\n",
        "        z_dist=186.6e-3,\n",
        "        num_layers=10,\n",
        "        tiles=5,            # 5×5 MLA\n",
        "        tile_size=3,         # each lenslet is 3×3\n",
        "              # small-world params:\n",
        "        sw_m=2,         # local span (how many previous layers to link)\n",
        "        sw_p=0.2,       # rewiring prob\n",
        "        sw_trainable=True,  # if True, learn weights for small-world links\n",
        "        sw_init_gamma=0.1,    # initial scale for small-world links\n",
        "        sw_seed=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.wavelength = wavelength\n",
        "        self.dx = dx\n",
        "        self.dy = dy\n",
        "        self.num_layers = num_layers\n",
        "        self.z_list = [z_dist] * num_layers\n",
        "        self.tiles = tiles\n",
        "        self.tile_size = tile_size\n",
        "        self.output_size = tiles * tile_size  # 5 × 3 = 15\n",
        "        self.hub = HubModule(self.output_size, hidden=128)  # Add to init\n",
        "\n",
        "\n",
        "        self.amp_list = nn.ParameterList([\n",
        "            nn.Parameter(0.5 * torch.ones(self.output_size, self.output_size))\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.phase_list = nn.ParameterList([\n",
        "            nn.Parameter(torch.zeros(self.output_size, self.output_size))\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Precompute the FFT grid for propagation (15×15)\n",
        "        self.register_buffer('fft_grid', self._create_fft_grid(), persistent=False)\n",
        "        # Detector: 10 regions tiled over the 15×15 output\n",
        "        self.register_buffer('detector_masks', self._create_detector_masks(), persistent=False)\n",
        "\n",
        "        # --- Small-world setup ---\n",
        "        self.sw_m = sw_m\n",
        "        self.sw_p = sw_p\n",
        "        if sw_seed is not None:\n",
        "          random.seed(sw_seed)\n",
        "        # Build small-world neighbors: for each layer i, a list of earlier layer indices\n",
        "        sw_neighbors = []\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            neigh = []\n",
        "            # local neighbors: previous sw_m layers\n",
        "\n",
        "            for offset in range(1, sw_m + 1):\n",
        "                j = i - offset\n",
        "                if j < 0:\n",
        "                    break\n",
        "                # decide whether to rewire\n",
        "                if random.random() < sw_p and i > 0:\n",
        "                    # pick a random earlier layer in [0, i-1], avoiding duplicates\n",
        "                    candidates = set(range(0, i)) - set(neigh)\n",
        "                    if candidates:\n",
        "                        j_rand = random.choice(list(candidates))\n",
        "                        neigh.append(j_rand)\n",
        "                    else:\n",
        "                        neigh.append(j)\n",
        "                else:\n",
        "                    neigh.append(j)\n",
        "            sw_neighbors.append(neigh)\n",
        "        # store as plain Python list (no gradient)\n",
        "        self.sw_neighbors = sw_neighbors\n",
        "\n",
        "        # Optional: trainable weights per small-world link\n",
        "        self.sw_trainable = sw_trainable\n",
        "        if sw_trainable:\n",
        "            # For each layer i, create a Parameter of shape (k_i,)\n",
        "            self.sw_weights = nn.ParameterList()\n",
        "            for i in range(num_layers):\n",
        "                k_i = len(self.sw_neighbors[i])\n",
        "                if k_i > 0:\n",
        "                    # initialize around sw_init_gamma\n",
        "                    init = torch.ones(k_i) * sw_init_gamma\n",
        "                    self.sw_weights.append(nn.Parameter(init))\n",
        "                else:\n",
        "                    # placeholder for consistency; won't be used in forward\n",
        "                    self.sw_weights.append(nn.Parameter(torch.zeros(0)))\n",
        "        else:\n",
        "            # fixed scale\n",
        "            self.sw_gamma = sw_init_gamma\n",
        "\n",
        "\n",
        "    def _create_fft_grid(self):\n",
        "        H = W = self.output_size  # 15\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        fx = torch.fft.fftfreq(W, d=self.dx, device=device)\n",
        "        fy = torch.fft.fftfreq(H, d=self.dy, device=device)\n",
        "        FX, FY = torch.meshgrid(fx, fy, indexing='xy')\n",
        "\n",
        "        k = 2 * np.pi / self.wavelength\n",
        "        arg = 1.0 - (self.wavelength * FX) ** 2 - (self.wavelength * FY) ** 2\n",
        "        arg = torch.clamp(arg, min=0.0)\n",
        "        return torch.sqrt(arg)\n",
        "\n",
        "    def _create_detector_masks(self):\n",
        "        H = W = self.output_size  # 15\n",
        "        masks = torch.zeros(10, H, W)\n",
        "\n",
        "        # Partition 15×15 into 10 regions (3 rows with 3 regions, 1 row with 1 region)\n",
        "        for i in range(10):\n",
        "            row = i // 3\n",
        "            col = i % 3\n",
        "\n",
        "            # Compute row boundaries\n",
        "            h_start = int(row * H / 4)\n",
        "            if row < 3:\n",
        "                h_end = int((row + 1) * H / 4)\n",
        "            else:\n",
        "                h_end = H  # Last row takes remaining space\n",
        "\n",
        "            # Compute column boundaries\n",
        "            if row < 3:\n",
        "                w_start = int(col * W / 3)\n",
        "                w_end = int((col + 1) * W / 3)\n",
        "            else:\n",
        "                w_start = 0\n",
        "                w_end = W  # Last row spans full width\n",
        "\n",
        "            masks[i, h_start:h_end, w_start:w_end] = 1.0\n",
        "\n",
        "        return masks\n",
        "\n",
        "    def propagate(self, U, z):\n",
        "        k = 2 * np.pi / self.wavelength\n",
        "        H_transfer = torch.exp(1j * k * z * self.fft_grid)  # (15×15)\n",
        "        U_fft = torch.fft.fft2(U)\n",
        "        U_prop = torch.fft.ifft2(U_fft * H_transfer)\n",
        "        return U_prop\n",
        "\n",
        "    def tile_input(self, U0):\n",
        "        \"\"\"\n",
        "        U0: (B, H_in, W_in) with H_in=W_in=15.\n",
        "        We split each 15×15 U0 into 25 patches of size 3×3 → build a 15×15 complex field.\n",
        "        \"\"\"\n",
        "        B, H, W = U0.shape  # H=W=15\n",
        "        return U0.to(torch.complex64)\n",
        "\n",
        "\n",
        "    def forward(self, U0):\n",
        "        \"\"\"\n",
        "        U0: (B, H_in, W_in) with H_in=W_in=15 (grayscale per channel).\n",
        "        1) tile_input → (B, 15, 15) complex\n",
        "        2) For each of the num_layers:\n",
        "            a) build composite mask (15×15) from 25 learned 3×3 tiles\n",
        "            b) multiply U * M, then propagate\n",
        "        3) Compute intensity → (B, 15,15) real → apply 10 detectors → (B,10) logits\n",
        "        \"\"\"\n",
        "        U = self.tile_input(U0)  # (B, 15, 15) complex\n",
        "\n",
        "        history = []                   # ← Step 1: initialize history\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            phase = torch.clamp(self.phase_list[i], -np.pi, np.pi)       # (15,15)\n",
        "            Mi = self.amp_list[i] * torch.exp(1j * phase)                # (15,15)\n",
        "            U = U * Mi\n",
        "\n",
        "            U = self.propagate(U, self.z_list[i])                        # (B,15,15) complex\n",
        "\n",
        "            #  --- Small-world aggregation ---\n",
        "            neigh = [j for j in self.sw_neighbors[i] if j < len(history) and history[j] is not None]\n",
        "            k_i = len(neigh)\n",
        "            if k_i > 0:\n",
        "              if self.sw_trainable:\n",
        "                weights_sw = self.sw_weights[i][:k_i] # Select only weights for valid neighbors\n",
        "                norm = math.sqrt(k_i)\n",
        "                for idx_j, j in enumerate(neigh):\n",
        "                  gamma_ij = weights_sw[idx_j] / norm\n",
        "                  U = U + gamma_ij * history[j]\n",
        "              else:\n",
        "                scale = self.sw_gamma / math.sqrt(k_i)\n",
        "                for j in neigh:\n",
        "                  U = U + scale * history[j]\n",
        "            # ----------------------------------\n",
        "\n",
        "            # 3) Append the *final* U for this layer\n",
        "            history.append(U)\n",
        "\n",
        "        # Ensure U is not None before calculating intensity\n",
        "        if U is not None:\n",
        "            I = U.real*2 + U.imag*2  # (B,15,15) real\n",
        "            logits = (I.unsqueeze(1) * self.detector_masks.unsqueeze(0)).sum(dim=(2, 3))\n",
        "        else:\n",
        "            # Handle the case where U might still be None (e.g., num_layers is 0)\n",
        "            logits = torch.zeros(U0.shape[0], 10, device=U0.device) # Or handle as appropriate\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "class HubModule(nn.Module):\n",
        "    def __init__(self, input_size, hidden=128):\n",
        "        super().__init__()\n",
        "        flat_dim = input_size * input_size\n",
        "        # Adjust input size to handle potentially fewer tensors\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(3 * flat_dim * 2, hidden),  # Max 3 previous layers, real+imag\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, flat_dim * 2)       # real+imag output\n",
        "        )\n",
        "        self.input_size = input_size\n",
        "\n",
        "    def forward(self, tensors):  # tensors: list of complex 2D fields\n",
        "        # Filter out None tensors and handle empty list\n",
        "        valid_tensors = [t for t in tensors if t is not None]\n",
        "        if not valid_tensors:\n",
        "            # Return a zero tensor of the expected output shape\n",
        "            return torch.zeros(1, self.input_size, self.input_size, dtype=torch.complex64, device=self.fc[0].weight.device)\n",
        "\n",
        "        # Split real and imag parts\n",
        "        reals = [t.real.view(t.shape[0], -1) for t in valid_tensors]\n",
        "        imags = [t.imag.view(t.shape[0], -1) for t in valid_tensors]\n",
        "\n",
        "        # Pad with zeros if fewer than 3 tensors\n",
        "        while len(reals) < 3:\n",
        "            reals.append(torch.zeros_like(reals[0]))\n",
        "            imags.append(torch.zeros_like(imags[0]))\n",
        "\n",
        "        x = torch.cat(reals + imags, dim=1)  # concat all\n",
        "        out = self.fc(x)\n",
        "        real_part, imag_part = out.chunk(2, dim=1)\n",
        "        complex_out = torch.complex(real_part, imag_part).view(\n",
        "            valid_tensors[0].shape[0], self.input_size, self.input_size)\n",
        "        return complex_out\n",
        "\n",
        "\n",
        "\n",
        "class RGB_FastONN_Ensemble(nn.Module):\n",
        "    def __init__(self, base_model_cls, n_models=10, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.models = nn.ModuleList([\n",
        "            base_model_cls(*args, **kwargs) for _ in range(n_models)\n",
        "        ])\n",
        "        self.weights = nn.Parameter(torch.ones(n_models) / n_models)  # learnable or fixed weights\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = []\n",
        "        for model in self.models:\n",
        "            out = model(x)  # shape: (B, 10)\n",
        "            outputs.append(out)\n",
        "        stacked = torch.stack(outputs, dim=0)  # shape: (30, B, 10)\n",
        "        weighted = self.weights.view(-1, 1, 1) * stacked\n",
        "        return weighted.sum(dim=0)  # shape: (B, 10)\n",
        "\n",
        "\n",
        "class RGB_FastONN(nn.Module):\n",
        "    \"\"\"Optical NN with parallel RGB processing paths using a 5×5 MLA over 15×15 per channel.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        wavelengths=[650e-9, 530e-9, 470e-9],\n",
        "        dx=1e-6,\n",
        "        dy=1e-6,\n",
        "        z_dist=186.6e-3,\n",
        "        num_layers=15,      # 15 layers per color path\n",
        "        tiles=5,            # 5×5 MLA\n",
        "        tile_size=3,        # each lenslet is 3×3\n",
        "        hidden_size=64\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.red_path = FastONNCore(\n",
        "            wavelength=wavelengths[0],\n",
        "            dx=dx, dy=dy,\n",
        "            z_dist=z_dist,\n",
        "            num_layers=num_layers,\n",
        "            tiles=tiles,\n",
        "            tile_size=tile_size\n",
        "        )\n",
        "        self.green_path = FastONNCore(\n",
        "            wavelength=wavelengths[1],\n",
        "            dx=dx, dy=dy,\n",
        "            z_dist=z_dist,\n",
        "            num_layers=num_layers,\n",
        "            tiles=tiles,\n",
        "            tile_size=tile_size\n",
        "        )\n",
        "        self.blue_path = FastONNCore(\n",
        "            wavelength=wavelengths[2],\n",
        "            dx=dx, dy=dy,\n",
        "            z_dist=z_dist,\n",
        "            num_layers=num_layers,\n",
        "            tiles=tiles,\n",
        "            tile_size=tile_size\n",
        "        )\n",
        "\n",
        "        # Electronic fusion MLP (3×10 → hidden_size → 10)\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(30, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_size, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, 3, 15, 15) after transforms and CenterCrop\n",
        "        r_out = self.red_path(x[:, 0])    # (B,10)\n",
        "        g_out = self.green_path(x[:, 1])  # (B,10)\n",
        "        b_out = self.blue_path(x[:, 2])   # (B,10)\n",
        "\n",
        "        combined = torch.cat([r_out, g_out, b_out], dim=1)  # (B,30)\n",
        "        return self.fusion(combined)                        # (B,10)\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return 100. * correct / total\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, test_loader, epochs=50, lr=0.001):\n",
        "    device = next(model.parameters()).device\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='max', factor=0.5, patience=5, verbose=True\n",
        "    )\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss, total_correct, total_samples = 0, 0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Gentle phase regularization\n",
        "            phase_reg = 0.0\n",
        "            for module in model.modules():\n",
        "                if isinstance(module, FastONNCore):\n",
        "                    for p in module.phase_list:\n",
        "                        phase_reg += 0.001 * p.abs().mean()\n",
        "            loss += phase_reg\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_correct += predicted.eq(labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "        train_loss = total_loss / total_samples\n",
        "        train_acc = 100.0 * total_correct / total_samples\n",
        "\n",
        "        test_acc = evaluate(model, test_loader)\n",
        "        scheduler.step(test_acc)\n",
        "\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            torch.save(model.state_dict(), \"best_rgb_onn_model.pth\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "    return best_acc\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    start_time = time.time()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Fixed transforms for RGB (3 channels)\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize(16),\n",
        "        transforms.CenterCrop(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # RGB normalization\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize(16),\n",
        "        transforms.CenterCrop(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    # Download datasets\n",
        "    train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=train_transform)\n",
        "    test_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=test_transform)\n",
        "\n",
        "\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # Instantiate model\n",
        "    model = RGB_FastONN(\n",
        "\n",
        "\n",
        "        wavelengths=[650e-9, 530e-9, 470e-9],\n",
        "        num_layers=15,\n",
        "        tiles=5,\n",
        "        tile_size=3,\n",
        "        hidden_size=64\n",
        "    ).to(device)\n",
        "    # model = torch.compile(model)\n",
        "\n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Trainable parameters: {total_params:,}\")\n",
        "\n",
        "    # Train the model\n",
        "    best_acc = train_model(\n",
        "        model, train_loader, test_loader,\n",
        "        epochs=50,\n",
        "        lr=0.001\n",
        "    )\n",
        "    print(f\"Best Test Accuracy: {best_acc:.2f}%\")\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    minutes = int(elapsed_time // 60)\n",
        "    seconds = int(elapsed_time % 60)\n",
        "    print(f\"Total training time: {minutes} min {seconds} sec\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TRiiIvqO-FVg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}