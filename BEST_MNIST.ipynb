{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ONN MODEL WITH MLA, SMALL WORLD SKIP CONNECTIONS AND SATURABLE ABSORBER(SA)"
      ],
      "metadata": {
        "id": "nkp3AOPhWxDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "\n",
        "# --- Config ---\n",
        "detector_layout = [3, 4, 3]  # 10 classes\n",
        "wavelength     = 480e-9\n",
        "image_size     = 14\n",
        "tiles          = 6\n",
        "output_size    = tiles * image_size\n",
        "num_classes    = sum(detector_layout)\n",
        "skip_probs     = [0.0, 0.25, 0.75]\n",
        "# Saturable absorber base params\n",
        "base_A0   = 0.1\n",
        "base_I_sat= 5e6\n",
        "base_A_ns = 0.005\n",
        "cascade_sas = 2\n",
        "min_dist  = 2\n",
        "max_dist  = 7\n",
        "\n",
        "# --- Device ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# --- Dataset (MNIST) ---\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "train_loader  = DataLoader(train_dataset, batch_size=128, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "test_loader   = DataLoader(test_dataset,  batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# --- Model with Small-World Skips + Saturable Absorber ---\n",
        "class OpticalLayer(nn.Module):\n",
        "    def __init__(self, size):\n",
        "        super().__init__()\n",
        "        self.phase = nn.Parameter(torch.randn(size, size) * 0.1)\n",
        "\n",
        "    def forward(self, x, kernel):\n",
        "        x     = x * torch.exp(1j * self.phase)\n",
        "        x_fft = torch.fft.fft2(x) * kernel\n",
        "        return torch.fft.ifft2(x_fft)\n",
        "\n",
        "class FastONNSmallWorldSA(nn.Module):\n",
        "    def __init__(self, num_layers=10, p=0.0):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([OpticalLayer(output_size) for _ in range(num_layers)])\n",
        "        # small-world skip\n",
        "        self.skip_connections = []\n",
        "        for i in range(num_layers):\n",
        "            for j in range(i+min_dist, min(i+max_dist+1, num_layers)):\n",
        "                if random.random() < p:\n",
        "                    self.skip_connections.append((i,j))\n",
        "        self.skip_weight = nn.ParameterDict({f\"{i}_{j}\": nn.Parameter(torch.tensor(0.5))\n",
        "                                            for i,j in self.skip_connections})\n",
        "        # saturable absorber params\n",
        "        self.A0    = nn.ParameterList([nn.Parameter(torch.tensor(base_A0)) for _ in range(num_layers)])\n",
        "        self.I_sat = nn.ParameterList([nn.Parameter(torch.tensor(base_I_sat)) for _ in range(num_layers)])\n",
        "        self.A_ns  = nn.ParameterList([nn.Parameter(torch.tensor(base_A_ns)) for _ in range(num_layers)])\n",
        "        # detector\n",
        "        self.detector_scale = nn.Parameter(torch.tensor([10.0], dtype=torch.float32))\n",
        "        self.fft_grid       = self._create_fft_grid().to(device)\n",
        "        self.detector_masks = self._create_detector_masks().to(device)\n",
        "\n",
        "    def _create_fft_grid(self):\n",
        "        fx = torch.fft.fftfreq(output_size, d=1e-6)\n",
        "        fy = torch.fft.fftfreq(output_size, d=1e-6)\n",
        "        FX, FY = torch.meshgrid(fx, fy, indexing='xy')\n",
        "        k = 2 * np.pi / wavelength\n",
        "        arg = torch.clamp(1 - (wavelength * FX)**2 - (wavelength * FY)**2, 0.0)\n",
        "        return torch.exp(1j * k * torch.sqrt(arg))\n",
        "\n",
        "    def _create_detector_masks(self):\n",
        "        masks=[]; H=W=output_size; band_h=H//3\n",
        "        for r,cols in enumerate(detector_layout):\n",
        "            cell_w=W//cols; y0=r*band_h; y1=y0+band_h\n",
        "            for c in range(cols):\n",
        "                x0=c*cell_w; x1=x0+cell_w\n",
        "                m=torch.zeros(H,W); m[y0:y1,x0:x1]=1.0; masks.append(m)\n",
        "        return torch.stack(masks)\n",
        "\n",
        "    def tile_input(self, x):\n",
        "        B=x.size(0)\n",
        "        x=x.view(B,1,1,image_size,image_size)\n",
        "        x=x.repeat(1,tiles,tiles,1,1)\n",
        "        x=x.permute(0,1,3,2,4).reshape(B,output_size,output_size)\n",
        "        return x.to(torch.complex64)\n",
        "\n",
        "    def _apply_sa(self, field, idx):\n",
        "        out = field\n",
        "        for _ in range(cascade_sas):\n",
        "            I = out.real**2 + out.imag**2\n",
        "            T = torch.exp(-((self.A0[idx]/(1+I/self.I_sat[idx])) + self.A_ns[idx]))\n",
        "            out = torch.sqrt(T) * out\n",
        "        return out\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.tile_input(x)\n",
        "        states = {0: x}\n",
        "        for idx, layer in enumerate(self.layers):\n",
        "            inp = x\n",
        "            # small-world skips\n",
        "            for i,j in self.skip_connections:\n",
        "                if j==idx:\n",
        "                    w = torch.sigmoid(self.skip_weight[f\"{i}_{j}\"])\n",
        "                    inp = inp + w * states[i]\n",
        "            # optical\n",
        "            x = layer(inp, self.fft_grid)\n",
        "            # saturable absorber\n",
        "            x = self._apply_sa(x, idx)\n",
        "            states[idx] = x\n",
        "        I = x.real**2 + x.imag**2\n",
        "        out = (I.unsqueeze(1)*self.detector_masks.unsqueeze(0)).sum(dim=(2,3))\n",
        "        return out * self.detector_scale\n",
        "\n",
        "# --- Training Loop across p values ---\n",
        "def evaluate(model, loader):\n",
        "    model.eval(); corr=tot=0\n",
        "    with torch.no_grad():\n",
        "        for imgs, lbls in loader:\n",
        "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
        "            preds = model(imgs).argmax(1)\n",
        "            corr += preds.eq(lbls).sum().item(); tot+=lbls.size(0)\n",
        "    return 100.0*corr/tot\n",
        "\n",
        "for p in skip_probs:\n",
        "    print(f\"\\n=== Rewiring p = {p} ===\")\n",
        "    random.seed(42); torch.manual_seed(42)\n",
        "    model = FastONNSmallWorldSA(num_layers=10, p=p).to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, 16):\n",
        "        model.train(); corr=tot=0; start=time.time()\n",
        "        for imgs, lbls in train_loader:\n",
        "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
        "            optimizer.zero_grad(); out=model(imgs)\n",
        "            loss=criterion(out,lbls); loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
        "            optimizer.step();\n",
        "            preds=out.argmax(1); corr+=preds.eq(lbls).sum().item(); tot+=lbls.size(0)\n",
        "        scheduler.step()\n",
        "        train_acc=100*corr/tot; val_acc=evaluate(model,test_loader)\n",
        "        print(f\"Epoch {epoch}/15 | Time: {time.time()-start:.1f}s | \"\n",
        "              f\"Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
        "    final_acc=evaluate(model,test_loader)\n",
        "    print(f\"Final Test Acc @ p={p}: {final_acc:.2f}%\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T22:49:41.997791Z",
          "iopub.execute_input": "2025-07-03T22:49:41.998183Z",
          "iopub.status.idle": "2025-07-03T23:12:07.345637Z",
          "shell.execute_reply.started": "2025-07-03T22:49:41.998151Z",
          "shell.execute_reply": "2025-07-03T23:12:07.344887Z"
        },
        "id": "RdFKtPodWco4",
        "outputId": "378a5d71-1605-497a-fc46-9497ea72bc4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n=== Rewiring p = 0.0 ===\nEpoch 1/15 | Time: 26.4s | Train Acc: 92.51% | Val Acc: 95.53%\nEpoch 2/15 | Time: 26.2s | Train Acc: 95.67% | Val Acc: 95.94%\nEpoch 3/15 | Time: 26.2s | Train Acc: 96.16% | Val Acc: 96.38%\nEpoch 4/15 | Time: 26.2s | Train Acc: 96.48% | Val Acc: 94.99%\nEpoch 5/15 | Time: 26.3s | Train Acc: 96.70% | Val Acc: 96.52%\nEpoch 6/15 | Time: 26.2s | Train Acc: 97.59% | Val Acc: 97.48%\nEpoch 7/15 | Time: 26.2s | Train Acc: 97.73% | Val Acc: 97.28%\nEpoch 8/15 | Time: 26.2s | Train Acc: 97.76% | Val Acc: 97.06%\nEpoch 9/15 | Time: 26.2s | Train Acc: 97.83% | Val Acc: 96.95%\nEpoch 10/15 | Time: 26.2s | Train Acc: 97.83% | Val Acc: 97.34%\nEpoch 11/15 | Time: 26.2s | Train Acc: 98.47% | Val Acc: 97.58%\nEpoch 12/15 | Time: 26.2s | Train Acc: 98.57% | Val Acc: 97.62%\nEpoch 13/15 | Time: 26.2s | Train Acc: 98.63% | Val Acc: 97.73%\nEpoch 14/15 | Time: 26.2s | Train Acc: 98.71% | Val Acc: 97.86%\nEpoch 15/15 | Time: 26.2s | Train Acc: 98.69% | Val Acc: 97.79%\nFinal Test Acc @ p=0.0: 97.79%\n\n=== Rewiring p = 0.25 ===\nEpoch 1/15 | Time: 29.5s | Train Acc: 93.40% | Val Acc: 96.72%\nEpoch 2/15 | Time: 29.5s | Train Acc: 96.73% | Val Acc: 96.66%\nEpoch 3/15 | Time: 29.5s | Train Acc: 97.27% | Val Acc: 97.02%\nEpoch 4/15 | Time: 29.5s | Train Acc: 97.49% | Val Acc: 97.49%\nEpoch 5/15 | Time: 29.5s | Train Acc: 97.79% | Val Acc: 97.27%\nEpoch 6/15 | Time: 29.5s | Train Acc: 98.49% | Val Acc: 97.98%\nEpoch 7/15 | Time: 29.5s | Train Acc: 98.67% | Val Acc: 97.86%\nEpoch 8/15 | Time: 29.5s | Train Acc: 98.75% | Val Acc: 98.07%\nEpoch 9/15 | Time: 29.5s | Train Acc: 98.82% | Val Acc: 97.85%\nEpoch 10/15 | Time: 29.5s | Train Acc: 98.76% | Val Acc: 97.79%\nEpoch 11/15 | Time: 29.5s | Train Acc: 99.31% | Val Acc: 97.91%\nEpoch 12/15 | Time: 29.5s | Train Acc: 99.41% | Val Acc: 97.96%\nEpoch 13/15 | Time: 29.5s | Train Acc: 99.43% | Val Acc: 97.97%\nEpoch 14/15 | Time: 29.5s | Train Acc: 99.44% | Val Acc: 97.87%\nEpoch 15/15 | Time: 29.5s | Train Acc: 99.47% | Val Acc: 98.00%\nFinal Test Acc @ p=0.25: 98.00%\n\n=== Rewiring p = 0.75 ===\nEpoch 1/15 | Time: 33.7s | Train Acc: 92.56% | Val Acc: 96.44%\nEpoch 2/15 | Time: 33.7s | Train Acc: 96.70% | Val Acc: 96.60%\nEpoch 3/15 | Time: 33.7s | Train Acc: 97.32% | Val Acc: 97.17%\nEpoch 4/15 | Time: 33.7s | Train Acc: 97.61% | Val Acc: 97.28%\nEpoch 5/15 | Time: 33.7s | Train Acc: 97.76% | Val Acc: 97.37%\nEpoch 6/15 | Time: 33.7s | Train Acc: 98.51% | Val Acc: 97.73%\nEpoch 7/15 | Time: 33.7s | Train Acc: 98.69% | Val Acc: 97.66%\nEpoch 8/15 | Time: 33.7s | Train Acc: 98.79% | Val Acc: 97.61%\nEpoch 9/15 | Time: 33.6s | Train Acc: 98.87% | Val Acc: 97.74%\nEpoch 10/15 | Time: 33.7s | Train Acc: 98.91% | Val Acc: 97.82%\nEpoch 11/15 | Time: 33.7s | Train Acc: 99.33% | Val Acc: 97.68%\nEpoch 12/15 | Time: 33.6s | Train Acc: 99.45% | Val Acc: 97.95%\nEpoch 13/15 | Time: 33.6s | Train Acc: 99.49% | Val Acc: 97.96%\nEpoch 14/15 | Time: 33.6s | Train Acc: 99.51% | Val Acc: 97.76%\nEpoch 15/15 | Time: 33.7s | Train Acc: 99.49% | Val Acc: 97.90%\nFinal Test Acc @ p=0.75: 97.90%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}